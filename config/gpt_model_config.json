{
    "models": [
        {
            "model": "gpt-4",
            "max_tokens": 1024,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "stream": false,
            "logprobs": null,
            "stop": "\n"
        },
        {
            "model": "gpt-3.5-turbo",
            "max_tokens": 1024,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "stream": false,
            "logprobs": null,
            "stop": "\n"
        }
    ]
}
